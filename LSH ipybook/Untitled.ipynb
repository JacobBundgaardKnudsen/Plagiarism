{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect, os\n",
    "from gensim.parsing import preprocessing as genPreProc\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from spacy import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDoc(dataPath):\n",
    "    with open(dataPath, encoding=\"utf8\", errors='ignore') as loadedDoc:\n",
    "        doc = loadedDoc.read()\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load('en')\n",
    "srcfolder = os.path.dirname(os.path.abspath(inspect.stack()[0][1]))\n",
    "datafolder = os.path.join(srcfolder, \"testDocuments\")   # change to ats_corpus for large data set\n",
    "filepath = os.path.join(datafolder, \"testDoc5.txt\")\n",
    "    \n",
    "document = loadDoc(filepath)\n",
    "\n",
    "document = loadDoc(filepath)\n",
    "genSettings2 = [lambda x: x.lower(), genPreProc.remove_stopwords, genPreProc.stem]\n",
    "step1preprocess = ' '.join(preprocess_string(document, filters=genSettings2))\n",
    "sentenceSplit = list(nlp(step1preprocess).sents)\n",
    "\n",
    "genSettings3 = [lambda x: genPreProc.strip_non_alphanum(x), genPreProc.strip_multiple_whitespaces]\n",
    "sentencePreprocess = [' '.join(preprocess_string(str(ite), filters=genSettings3)) for ite in sentenceSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['found abdallah ibn yasin almoravid capit marrakesh citi rule hous found 1062',\n",
       " 'anden sætning result king ishaq ibn ali kill marrakesh april 1147 almohad caliphate replac rule dynasti morocco al andalus',\n",
       " 'dynasti origin lamtuna gudala nomad berber tribe sahara travers territori draa niger seneg rivers',\n",
       " '4 sætning weknf ælekfnlejkrgnwekrlj wbegrlergb lkbjregw bljkwgrbl jlkb',\n",
       " '5 sætning werlnkqæ qær nlk knqqjqv v vg aa',\n",
       " 'author contributor samba file server co inventor rsync algorithm synchronis tool',\n",
       " 'origin author rzip us similar algorithm rsync',\n",
       " 'develop spamsum base locality sensit hash algorithms h author knightcap reinforcement learn base chess engine tridgel leader hack tivo work australia us pal video format in april 2005 tridgel tri produc free softwar now known sourcepuller interoper bitkeep sourc code repository',\n",
       " 'cite reason bitmov revok licens allow linux develop free us bitkeep product',\n",
       " 'linu torvalds creator linux kernel tridgel involv public debat events tridgel state that have bought own bitkeep äì have agre licens äì violat it analyz protocol ethically samba tridgell involv project result']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load('en')\n",
    "srcfolder = os.path.dirname(os.path.abspath(inspect.stack()[0][1]))\n",
    "datafolder = os.path.join(srcfolder, \"WikiPages\")   # change to ats_corpus for large data set\n",
    "filepath = os.path.join(datafolder, \"Andrew Tridgell.txt\")\n",
    "    \n",
    "document = loadDoc(filepath)\n",
    "\n",
    "document = loadDoc(filepath)\n",
    "genSettings2 = [lambda x: x.lower(), genPreProc.remove_stopwords, genPreProc.stem]\n",
    "step1preprocess = ' '.join(preprocess_string(document, filters=genSettings2))\n",
    "sentenceSplit = list(nlp(step1preprocess).sents)\n",
    "\n",
    "genSettings3 = [lambda x: genPreProc.strip_non_alphanum(x), genPreProc.strip_multiple_whitespaces]\n",
    "test = [' '.join(preprocess_string(str(ite), filters=genSettings3)) for ite in sentenceSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'origin author rzip us similar algorithm rsync'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'origin author rzip us similar algorithm rsync'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load('en')\n",
    "srcfolder = os.path.dirname(os.path.abspath(inspect.stack()[0][1]))\n",
    "datafolder = os.path.join(srcfolder, \"WikiPages\")   # change to ats_corpus for large data set\n",
    "filepath = os.path.join(datafolder, \"Almoravid dynasty.txt\")\n",
    "    \n",
    "document = loadDoc(filepath)\n",
    "\n",
    "document = loadDoc(filepath)\n",
    "genSettings2 = [lambda x: x.lower(), genPreProc.remove_stopwords, genPreProc.stem]\n",
    "step1preprocess = ' '.join(preprocess_string(document, filters=genSettings2))\n",
    "sentenceSplit = list(nlp(step1preprocess).sents)\n",
    "\n",
    "genSettings3 = [lambda x: genPreProc.strip_non_alphanum(x), genPreProc.strip_multiple_whitespaces]\n",
    "test = [' '.join(preprocess_string(str(ite), filters=genSettings3)) for ite in sentenceSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dynasti origin lamtuna gudala nomad berber tribe sahara travers territori draa niger seneg rivers'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dynasti origin lamtuna gudala nomad berber tribe sahara travers territori draa niger seneg rivers th'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cite reason bitmov revok licens allow linux develop free us bitkeep product'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cite reason bitmov revok licens allow linux develop free us bitkeep product'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = load('en')\n",
    "srcfolder = os.path.dirname(os.path.abspath(inspect.stack()[0][1]))\n",
    "datafolder = os.path.join(srcfolder, \"WikiPages\")   # change to ats_corpus for large data set\n",
    "filepath = os.path.join(datafolder, \"Almoravid dynasty.txt\")\n",
    "    \n",
    "document = loadDoc(filepath)\n",
    "\n",
    "document = loadDoc(filepath)\n",
    "genSettings2 = [lambda x: x.lower(), genPreProc.remove_stopwords, genPreProc.stem]\n",
    "step1preprocess = ' '.join(preprocess_string(document, filters=genSettings2))\n",
    "sentenceSplit = list(nlp(step1preprocess).sents)\n",
    "\n",
    "genSettings3 = [lambda x: genPreProc.strip_non_alphanum(x), genPreProc.strip_multiple_whitespaces]\n",
    "test = [' '.join(preprocess_string(str(ite), filters=genSettings3)) for ite in sentenceSplit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'found abdallah ibn yasin almoravid capit marrakesh citi rule hous found 1062'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'found abdallah ibn yasin almoravid capit marrakesh citi rule hous found 1062'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'develop spamsum base locality sensit hash algorithms h author knightcap reinforcement learn base chess engine tridgel leader hack tivo work australia us pal video format in april 2005 tridgel tri produc free softwar now known sourcepuller interoper bitkeep sourc code repository'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencePreprocess[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'develop spamsum base locality sensit hash algorithms h author knightcap reinforcement learn base chess engine tridgel leader hack tivo work australia us pal video format in april 2005 tridgel tri produc free softwar now known sourcepuller interoper bitkeep sourc code repository'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
